noise=arima.sim(n=length(x),list(ar=c(0.5)),sd=0.1)
#mu=doppler(x)+eps/10
mu=(exp(1)^(10*x-5))/(1+exp(1)^(10*x-5))
y=mu+noise
#Nason's Book
yhat<-nason(y)$yhat
plot(y)
lines(yhat,col=4,lwd=2)
#simulate data
x=seq(0,1,length.out=256)
noise=arima.sim(n=length(x),list(ar=c(0.5)),sd=0.1)
#mu=doppler(x)+eps/10
mu=(exp(1)^(10*x-5))/(1+exp(1)^(10*x-5))
y=mu+noise
#Nason's Book
yhat<-nason(y)$yhat
plot(y)
lines(yhat,col=4,lwd=2)
x=seq(0,1,length.out=256)
noise=arima.sim(n=length(x),list(ar=c(0.5)),sd=0.1)
mu=doppler(x)+noise/10
y=mu+noise
yhat<-nason(y)$yhat
plot(y)
lines(yhat,col=4,lwd=2)
getwd()
setwd("/Users/francisco/Dropbox/Codigo Cerrar/Wang")
source("sourceWang.R")
#simulate data
x=seq(0,1,length.out=256)
#mu=(exp(1)^(10*x-5))/(1+exp(1)^(10*x-5))
mu=doppler(x)+noise/10
noise=arima.sim(n=length(mu),list(ar=c(0.5)),sd=0.1)
y=mu+noise
#Cochrane-Orcut iterations (Wang)
o<-CochraneOrcut(num.knots=5,bdeg=2,y=y)
plot(y)
lines(o$yhat,lwd=2,col=4)
library(funtimes)
###############
#HVK estimator
##############
#based on:
#Hall and Van Keilegom 2003.
HVKmethod<-function(xvec,m1,m2,Y){
# only consider AR 1 errors (can be extended)
# xvec is [0,1] equidistant
# Y is the signal
# => returns h.opt, R.eigenvalues, fhat
#requires (to compute the Gassler et al. kernel estimators)
library(funtimes) #to get the phi's (already implemented by peps. at the University of maryland)
library(nlme) #to get the covariance given phi's. Known and implemented for ARMA's in nlme
n <- length(xvec)
if(is.null(m2)) m2 <- n^0.5
if(is.null(m1)) m1 <- n^0.4
h.set<-seq(0.06,0.94,length.out = 45)
#hat estimator#############################################
K<-function(x){
x[abs(x)>1]<-NA
o<-((15/16)*(1-x^2)^2)
o[is.na(o)]<-0
o
}
s1 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(K((x-xvec)/h)*(x-xvec)^1)
}
s2 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(K((x-xvec)/h)*((x-xvec)^2))
}
w <- function(x,xvec,k,h){
K((x-xvec[k])/h)*(s2(x,xvec,h)-(x-xvec[k])*s1(x,xvec,h))
}
ghat <- function(xvec,h,Y){
n<-length(xvec)
ones<-rep(1,n)
W<-matrix(NA,n,n)
for(i in 1:n){W[i,]=w(x=xvec[i],xvec=xvec,k=1:n,h)}
W%*%Y/W%*%ones
}
#ghatloo is ghat with leave one out (for cross-validation)
ghatloo <- function(xvec,h,Y){
n<-length(xvec)
ones<-rep(1,n)
W<-matrix(NA,n,n)
o<-rep(NA,n)
for(i in 1:n){W[i,]=w(x=xvec[i],xvec=xvec[-i],k=1:n,h)}
W<-W[,-n]
for(i in 1:n){
o[i]<-(W[i,]%*%Y[-i])/(W[i,]%*%ones[-i])
}
o
}
Hall.gamma0 <- function(m2,m1,Y){
n=length(Y);
gamma0=0;
for(i in m1:m2){
temp1 = Y[1:(n-i)]
temp2 = Y[(i+1):n]
temp = mean( (temp2-temp1)^2 )/2
gamma0 = gamma0 + temp
}
return( gamma0/(m2-m1+1) )
}
#end of hat estimator######################################
#tilde estimator###########################################
L<-function(x){
x[abs(x)>1]<-NA
x[x<0]<-NA
o<-((15/16)*(1-x^2)^2)
o[is.na(o)]<-0
o
}
r1 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(L((x-xvec)/h)*(x-xvec)^1)
}
r2 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(L((x-xvec)/h)*((x-xvec)^2))
}
v <- function(x,xvec,k,h){
L((x-xvec[k])/h)*(r2(x,xvec,h)-(x-xvec[k])*r1(x,xvec,h))
}
#end of tilde estimator####################################
phi.hat <- HVK(X=as.vector(Y),m1=m1,m2=m2,ar.order=1)
myDATA <- data.frame(X=Y,index=1:n)
csARMA <- corARMA(phi.hat, form = ~index, p = 1,q=0);
csARMA <- Initialize(csARMA, data = myDATA)
R <- corMatrix(csARMA)
R.eigenvalues<-Re(eigen(R)$values)
CV<-rep(NA,length(h.set))
for(i in 1:length(h.set)){
fit<-ghatloo(xvec=xvec,h=h.set[i],Y=y)
error<-y-fit
difference<-c(na.omit(error-phi.hat*c(NA,error[-n])))
CV[i]<-sum((difference)^2)/length(difference)
}
h.hat<-h.set[which.min(CV)]
f.hat <- ghat(xvec=xvec,h=h.hat,Y=y)
sigma2.hat<-Hall.gamma0(m2=m2,m1=m1,Y=y)
list(h.hat=h.hat, R.eigenvalues=R.eigenvalues,f.hat=f.hat,sigma2.hat=sigma2.hat)
}
library(funtimes)
###############
#HVK estimator
##############
#based on:
#Hall and Van Keilegom 2003.
HVKmethod<-function(xvec,m1,m2,Y){
# only consider AR 1 errors (can be extended)
# xvec is [0,1] equidistant
# Y is the signal
# => returns h.opt, R.eigenvalues, fhat
#requires (to compute the Gassler et al. kernel estimators)
library(funtimes) #to get the phi's (already implemented by peps. at the University of maryland)
library(nlme) #to get the covariance given phi's. Known and implemented for ARMA's in nlme
n <- length(xvec)
if(is.null(m2)) m2 <- n^0.5
if(is.null(m1)) m1 <- n^0.4
h.set<-seq(0.06,0.94,length.out = 45)
#hat estimator#############################################
K<-function(x){
x[abs(x)>1]<-NA
o<-((15/16)*(1-x^2)^2)
o[is.na(o)]<-0
o
}
s1 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(K((x-xvec)/h)*(x-xvec)^1)
}
s2 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(K((x-xvec)/h)*((x-xvec)^2))
}
w <- function(x,xvec,k,h){
K((x-xvec[k])/h)*(s2(x,xvec,h)-(x-xvec[k])*s1(x,xvec,h))
}
ghat <- function(xvec,h,Y){
n<-length(xvec)
ones<-rep(1,n)
W<-matrix(NA,n,n)
for(i in 1:n){W[i,]=w(x=xvec[i],xvec=xvec,k=1:n,h)}
W%*%Y/W%*%ones
}
#ghatloo is ghat with leave one out (for cross-validation)
ghatloo <- function(xvec,h,Y){
n<-length(xvec)
ones<-rep(1,n)
W<-matrix(NA,n,n)
o<-rep(NA,n)
for(i in 1:n){W[i,]=w(x=xvec[i],xvec=xvec[-i],k=1:n,h)}
W<-W[,-n]
for(i in 1:n){
o[i]<-(W[i,]%*%Y[-i])/(W[i,]%*%ones[-i])
}
o
}
Hall.gamma0 <- function(m2,m1,Y){
n=length(Y);
gamma0=0;
for(i in m1:m2){
temp1 = Y[1:(n-i)]
temp2 = Y[(i+1):n]
temp = mean( (temp2-temp1)^2 )/2
gamma0 = gamma0 + temp
}
return( gamma0/(m2-m1+1) )
}
#end of hat estimator######################################
#tilde estimator###########################################
L<-function(x){
x[abs(x)>1]<-NA
x[x<0]<-NA
o<-((15/16)*(1-x^2)^2)
o[is.na(o)]<-0
o
}
r1 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(L((x-xvec)/h)*(x-xvec)^1)
}
r2 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(L((x-xvec)/h)*((x-xvec)^2))
}
v <- function(x,xvec,k,h){
L((x-xvec[k])/h)*(r2(x,xvec,h)-(x-xvec[k])*r1(x,xvec,h))
}
#end of tilde estimator####################################
phi.hat <- HVK(X=as.vector(Y),m1=m1,m2=m2,ar.order=1)
myDATA <- data.frame(X=Y,index=1:n)
csARMA <- corARMA(phi.hat, form = ~index, p = 1,q=0);
csARMA <- Initialize(csARMA, data = myDATA)
R <- corMatrix(csARMA)
R.eigenvalues<-Re(eigen(R)$values)
CV<-rep(NA,length(h.set))
for(i in 1:length(h.set)){
fit<-ghatloo(xvec=xvec,h=h.set[i],Y=y)
error<-y-fit
difference<-c(na.omit(error-phi.hat*c(NA,error[-n])))
CV[i]<-sum((difference)^2)/length(difference)
}
h.hat<-h.set[which.min(CV)]
f.hat <- ghat(xvec=xvec,h=h.hat,Y=y)
sigma2.hat<-Hall.gamma0(m2=m2,m1=m1,Y=y)
list(h.hat=h.hat, R.eigenvalues=R.eigenvalues,f.hat=f.hat,sigma2.hat=sigma2.hat)
}
#simulate data
x=seq(0,1,length.out=256)
mu=(exp(1)^(10*x-5))/(1+exp(1)^(10*x-5))
#mu=doppler(x)+noise/10
noise=arima.sim(n=length(mu),list(ar=c(0.5)),sd=0.1)
y=mu+noise
plot(y)
o<-HVKmethod(xvec=x,m1=NULL,m2=NULL,Y=y)
o$f.hat
library(funtimes)
###############
#HVK estimator
##############
#based on:
#Hall and Van Keilegom 2003.
HVKmethod<-function(xvec,m1,m2,Y){
# only consider AR 1 errors (can be extended)
# xvec is [0,1] equidistant
# Y is the signal
# => returns h.opt, R.eigenvalues, fhat
#requires (to compute the Gassler et al. kernel estimators)
library(funtimes) #to get the phi's (already implemented by peps. at the University of maryland)
library(nlme) #to get the covariance given phi's. Known and implemented for ARMA's in nlme
n <- length(xvec)
if(is.null(m2)) m2 <- n^0.5
if(is.null(m1)) m1 <- n^0.4
h.set<-seq(0.06,0.94,length.out = 45)
#hat estimator#############################################
K<-function(x){
x[abs(x)>1]<-NA
o<-((15/16)*(1-x^2)^2)
o[is.na(o)]<-0
o
}
s1 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(K((x-xvec)/h)*(x-xvec)^1)
}
s2 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(K((x-xvec)/h)*((x-xvec)^2))
}
w <- function(x,xvec,k,h){
K((x-xvec[k])/h)*(s2(x,xvec,h)-(x-xvec[k])*s1(x,xvec,h))
}
ghat <- function(xvec,h,Y){
n<-length(xvec)
ones<-rep(1,n)
W<-matrix(NA,n,n)
for(i in 1:n){W[i,]=w(x=xvec[i],xvec=xvec,k=1:n,h)}
W%*%Y/W%*%ones
}
#ghatloo is ghat with leave one out (for cross-validation)
ghatloo <- function(xvec,h,Y){
n<-length(xvec)
ones<-rep(1,n)
W<-matrix(NA,n,n)
o<-rep(NA,n)
for(i in 1:n){W[i,]=w(x=xvec[i],xvec=xvec[-i],k=1:n,h)}
W<-W[,-n]
for(i in 1:n){
o[i]<-(W[i,]%*%Y[-i])/(W[i,]%*%ones[-i])
}
o
}
Hall.gamma0 <- function(m2,m1,Y){
n=length(Y);
gamma0=0;
for(i in m1:m2){
temp1 = Y[1:(n-i)]
temp2 = Y[(i+1):n]
temp = mean( (temp2-temp1)^2 )/2
gamma0 = gamma0 + temp
}
return( gamma0/(m2-m1+1) )
}
#end of hat estimator######################################
#tilde estimator###########################################
L<-function(x){
x[abs(x)>1]<-NA
x[x<0]<-NA
o<-((15/16)*(1-x^2)^2)
o[is.na(o)]<-0
o
}
r1 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(L((x-xvec)/h)*(x-xvec)^1)
}
r2 <- function(x,xvec,h){
n<-length(xvec)
((n*h)^(-1))*sum(L((x-xvec)/h)*((x-xvec)^2))
}
v <- function(x,xvec,k,h){
L((x-xvec[k])/h)*(r2(x,xvec,h)-(x-xvec[k])*r1(x,xvec,h))
}
#end of tilde estimator####################################
phi.hat <- HVK(X=as.vector(Y),m1=m1,m2=m2,ar.order=1)
myDATA <- data.frame(X=Y,index=1:n)
csARMA <- corARMA(phi.hat, form = ~index, p = 1,q=0);
csARMA <- Initialize(csARMA, data = myDATA)
R <- corMatrix(csARMA)
R.eigenvalues<-Re(eigen(R)$values)
CV<-rep(NA,length(h.set))
for(i in 1:length(h.set)){
fit<-ghatloo(xvec=xvec,h=h.set[i],Y=y)
error<-y-fit
difference<-c(na.omit(error-phi.hat*c(NA,error[-n])))
CV[i]<-sum((difference)^2)/length(difference)
}
h.hat<-h.set[which.min(CV)]
f.hat <- ghat(xvec=xvec,h=h.hat,Y=y)
sigma2.hat<-Hall.gamma0(m2=m2,m1=m1,Y=y)
#list(h.hat=h.hat, R.eigenvalues=R.eigenvalues,f.hat=f.hat,sigma2.hat=sigma2.hat)
list(Rhat=R,yhat=f.hat)
}
source("sourceHVK.R")
#simulate data
x=seq(0,1,length.out=256)
mu=(exp(1)^(10*x-5))/(1+exp(1)^(10*x-5))
#mu=doppler(x)+noise/10
noise=arima.sim(n=length(mu),list(ar=c(0.5)),sd=0.1)
y=mu+noise
#HVK
o<-HVKmethod(xvec=x,m1=NULL,m2=NULL,Y=y)
plot(y)
lines(o$yhat,lwd=2,col=4)
library(funtimes)
###############
#HERR estimator
##############
#based on:
#Herrmann et al. 1992.
Her<-function(xvec,m,Y){
# considers m-dependent errors
# xvec is [0,1] equidistant
# Y is the signal
# m is the dependence degree.
# => returns h.opt, R.eigenvalues, fhat
#requires (to compute the Gassler et al. kernel estimators)
library(lokern)
n<-length(xvec)
xgrid<-seq(-1,1,length.out = n)
dx<-diff(xvec)[1]
dxgrid<-diff(xgrid)[1]
#functions needed
aux.poly <- function(d){
return( 1 + d + d^2 )
}
gap.estimator <- function(m,d,v){ # Difference-based estimate of length 2(m+1) and length 3 calculated on vector v
n<- length(v)
sum((v[1:(n-2*(m+1))] - (1+d)*v[(m+2):(n-m-1)] + d*v[(2*m+3):n])^2)/( 2*aux.poly(d)*(n-2*(m+1)) )
}
gkH<-function(m,k,v){
n=length(v)
aux<-gap.estimator(m,1,v)
alphak<-(m+k+1)/(2*(m+1))
betak<--alphak*( (k/(m+k+1))^2 + ((m+1)/(m+k+1))^2 + 1)
temp<-alphak*sum( ( (k+m+1)*v[(k+1):(n-(m+1))] - k*v[(m+k+2):n] - (m+1)*v[1:(n-k-m-1)] )^2 )/((k+m+1)^2*(n-m-k-1))
-(aux*betak+temp)
}
gkHn<-function(m,k,v){
n<-length(v)
aux<-gap.estimator(m,1,v)
alphak<-(m+k+1)/(2*(m+1))
betak<--alphak*( (k/(m+k+1))^2 + ((m+1)/(m+k+1))^2 + 1)
temp<- (alphak/((m+k+1)^2*(n-m-1-k)))*sum( ((m+k+1)*v[(m+2):(n-k)] - (m+1)*v[(m+2+k):n] - k*v[1:(n-k-m-1)])^2 )
-(aux*betak+temp)
}
covarianceH<-function(m,v){
# l=length(v)
cov<- numeric(m)
for(i in 1:m){
cov[i] <- gkH(m,i,v)
}
# cov[ cov < 0 ] <- 0
c(gap.estimator(m,1,v),cov)
}
covarianceHn<-function(m,v){
# l=length(v)
cov<- numeric(m)
for(i in 1:m){
cov[i] <- gkHn(m,i,v)
}
# cov[ cov < 0 ] <- 0
c(gap.estimator(m,1,v),cov)
}
# non-negative function with support in x and non-vanishing derivatives at the borders
v<-function(x){
mu=0.5
sigma=0.2
(1/(sqrt(2*pi)*sigma))*exp(-((x-mu)^2)/(2*sigma^2))
}
# a fourth degree kernel (need to use the second derivative)
W<-function(x){
x[abs(x)>1]<-NA
o<-((15/16)*(1-x^2)^2)
o[is.na(o)]<-0
o
}
ghat<-function(xvec,b,sigma,Y){
glkerns(x=xvec, y=Y, deriv = 0, x.out=xvec,
korder= 4, hetero=FALSE, is.rand=FALSE,
inputb= FALSE,
m1 = 400, xl=NULL, xu=NULL,
s=NULL, sig=sigma, bandwidth=NULL, trace.lev = 0)$est
}
g2hat<-function(xvec,b,sigma,Y){
glkerns(x=xvec, y=Y, deriv = 2, x.out=xvec,
korder= 4, hetero=FALSE, is.rand=FALSE,
inputb= FALSE,
m1 = 400, xl=NULL, xu=NULL,
s=NULL, sig=sigma, bandwidth=NULL, trace.lev = 0)$est
}
#####################
#bandwidth selection
#####################
#input
C1 <- sum(v(x=xvec)*dx)*sum((W(x=xgrid)^2)*dxgrid)
C2 <- sum(((xgrid)^2)*W(x=xgrid)*dxgrid)
covvec <- covarianceH(m=m,v=y)
sigma<-sqrt(covvec[1])
gammavec<-covvec[-1]
gammavec[gammavec<10^(-2)] <- 0
fr<-rep(0,n)
fr[1:length(covarianceH(m,Y))]<-covarianceH(m,Y)/covarianceH(m,Y)[1]
R<-toeplitz(fr)
R.eigenvalues<-Re(eigen(R)$values)
S <- sigma^2+2*sum(gammavec)
sigma2.hat<-sigma^2
# loop
bvec<-rep(NA,12)
bvec[1]<-1/n
for(i in 2:12){
g2vec<-g2hat(xvec=xvec,b=bvec[i-1]*(n^0.1),sigma=sqrt(sigma2.hat),Y=y)
bvec[i]<-((C1*S)/(n*(C2^2)*(sum((v(xvec)*(g2vec^2))*dx))))^(1/5)
}
h.hat<-(bvec)[12]
f.hat<-ghat(xvec=xvec,b=b.hat,sigma=sqrt(sigma2.hat),Y=y)
#list(h.hat=h.hat, R.eigenvalues=R.eigenvalues,f.hat=f.hat,sigma2.hat=sigma2.hat)
list(Rhat=R,yhat=f.hat)
}
#simulate data
x=seq(0,1,length.out=256)
#mu=(exp(1)^(10*x-5))/(1+exp(1)^(10*x-5))
mu=doppler(x)+noise/10
noise=arima.sim(n=length(mu),list(ar=c(0.5)),sd=0.1)
y=mu+noise
#Herrman
o<-Her(xvec=x,m=12,Y=y)
plot(y)
lines(o$yhat,lwd=2,col=4)
#simulate data
x=seq(0,1,length.out=256)
mu=(exp(1)^(10*x-5))/(1+exp(1)^(10*x-5))
#mu=doppler(x)+noise/10
noise=arima.sim(n=length(mu),list(ar=c(0.5)),sd=0.1)
y=mu+noise
#Herrman
o<-Her(xvec=x,m=12,Y=y)
plot(y)
lines(o$yhat,lwd=2,col=4)
